{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7571df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:10-20\n",
      "Test:10-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0163.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0163.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:00<00:02,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0082.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0082.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:00<00:02,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0255.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0255.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:01,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0236.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0236.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:01<00:01,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0002.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0002.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:01<00:01,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0139.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0139.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:01<00:01,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0291.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0291.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:01<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0077.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0077.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:02<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0240.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0240.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:02<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0081.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0081.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.86it/s]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0239.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0239.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0324.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0324.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0044.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0044.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0004.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0004.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:00<00:00, 30.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0005.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0005.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0001.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0001.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0319.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0319.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0235.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0235.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:00<00:00, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0162.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0162.gif\n",
      "(605, 700, 3) (605, 700)\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\images\\im0003.tif\n",
      "C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig\\training\\1st_manual\\im0003.gif\n",
      "(605, 700, 3) (605, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 29.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from tensorflow import keras\n",
    "from tensorflow import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "# from keras.layers.core import Dropout, Lambda\n",
    "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "# from tensorflow.keras.layers.pooling import MaxPooling2D\n",
    "# from tensorflow.keras.layers.merge import concatenate\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import data, io, filters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from pylab import imread,subplot,imshow,show\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "\n",
    "# import keras\n",
    "# from keras import losses\n",
    "# from keras import backend as K\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.layers import Conv2D\n",
    "# from keras.layers import Conv1D\n",
    "# from keras.layers import MaxPooling2D\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers import concatenate\n",
    "# from keras.layers import Conv2DTranspose\n",
    "# from keras import optimizers\n",
    "# from keras.layers import Conv1D\n",
    "# from keras.optimizers import SGD #Stochastic Gradient Descent Optimize\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "# from keras.layers import GlobalAveragePooling2D, Input, multiply, LocallyConnected2D, Lambda, ReLU\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import BatchNormalization\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "# from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "# from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "# from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "# from keras.layers.merge import concatenate, add\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "from albumentations import HorizontalFlip, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion, CoarseDropout\n",
    "import imageio\n",
    "from sklearn.metrics import *\n",
    "from glob import glob\n",
    "\n",
    "# Check for path existance if not make a new dir\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "# load dataseet\n",
    "def load_data(path):\n",
    "    #\"\"\"X = Images and Y=masks\"\"\" #true for testing and training\n",
    "    train_all = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "    train_all = np.random.permutation(train_all)\n",
    "    number_for_train = 10\n",
    "    train_x = train_all[:number_for_train]\n",
    "#     print(train_x)\n",
    "    train_y = sorted(glob(os.path.join(path, \"training\", \"images\", \"*.tif\")))\n",
    "    test_x = train_all[number_for_train:]\n",
    "#     print(test_x)\n",
    "    test_y = sorted(glob(os.path.join(path, \"training\", \"1st_manual\", \"*.gif\")))\n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "\n",
    "\n",
    "def augment_data(images, masks, save_path, augment=True):\n",
    "    H = 512\n",
    "    W = 512\n",
    "    \n",
    "    for idx, (x,y) in tqdm(enumerate(zip(images,masks)), total = len(images)):\n",
    "        name = x.split (\"\\\\\") [- 1] .split (\".\") [0]\n",
    "#         print(name)\n",
    "        print(x)\n",
    "        # reading image and mask\n",
    "        x_aaa = x\n",
    "        x = cv2.imread(x,cv2.IMREAD_COLOR)\n",
    "        x_aaa = x_aaa.replace('images','1st_manual')\n",
    "        aaa = x_aaa.replace('tif','gif')\n",
    "        print(aaa)\n",
    "        y = imageio.mimread(aaa)[0]\n",
    "        print(x.shape, y.shape)\n",
    "        if augment == True:\n",
    "            aug = HorizontalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1 = augmented[\"image\"]\n",
    "            y1 = augmented[\"mask\"]\n",
    "\n",
    "            aug = VerticalFlip(p=1.0)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x2 = augmented[\"image\"]\n",
    "            y2 = augmented[\"mask\"]\n",
    "\n",
    "            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x3 = augmented['image']\n",
    "            y3 = augmented['mask']\n",
    "\n",
    "            aug = GridDistortion(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x4 = augmented['image']\n",
    "            y4 = augmented['mask']\n",
    "\n",
    "            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x5 = augmented['image']\n",
    "            y5 = augmented['mask']\n",
    "\n",
    "            X = [x, x1, x2, x3, x4, x5]\n",
    "            Y = [y, y1, y2, y3, y4, y5]\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "            \n",
    "        index = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            i = cv2.resize(i, (W, H))\n",
    "            m = cv2.resize(m, (W, H))\n",
    "\n",
    "            if len(X) == 1:\n",
    "                tmp_image_name = f\"{name}.jpg\"\n",
    "                tmp_mask_name = f\"{name}.jpg\"\n",
    "            else:\n",
    "                tmp_image_name = f\"{name}_{index}.jpg\"\n",
    "                tmp_mask_name = f\"{name}_{index}.jpg\"\n",
    "\n",
    "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    seed = 42\n",
    "    random.seed = seed\n",
    "    np.random.seed = seed\n",
    "     \n",
    "    # load data \n",
    "    data_path = 'C:/Users/aqsas/OneDrive/Documents/College stuff/ECE_599_Thesis/datasets/R2UNet/New_data_10_10/orig'\n",
    "    (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
    "    print(f\"Train:{len(train_x)}-{len(train_y)}\")\n",
    "    print(f\"Test:{len(test_x)}-{len(test_y)}\")\n",
    "    # create directories\n",
    "    create_dir(\"new_data/train/image\")\n",
    "    create_dir(\"new_data/train/mask\")\n",
    "    create_dir(\"new_data/test/image\")\n",
    "    create_dir(\"new_data/test/mask\")\n",
    "    \n",
    "    #augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
    "    augment_data(train_x, train_y, \"new_data/train/\", augment=True)\n",
    "    augment_data(test_x, test_y, \"new_data/test/\", augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbeaf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 32) 128         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 32) 9248        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 32) 128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 32) 9248        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 512, 32) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 512, 32) 128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 512, 512, 32) 9248        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 512, 512, 32) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512, 512, 32) 128         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512, 512, 32) 0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512, 512, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512, 512, 32) 128         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 512, 32) 0           conv2d[0][0]                     \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 32) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 64) 2112        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 256, 64) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256, 64) 256         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 64) 256         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256, 256, 64) 256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 256, 64) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256, 256, 64) 256         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 64) 36928       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256, 256, 64) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256, 256, 64) 256         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 256, 256, 64) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256, 256, 64) 256         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 256, 64) 0           conv2d_5[0][0]                   \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 128 8320        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 128 147584      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 128, 128 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 128, 128 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 128 512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 128 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 128 512         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 128 147584      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 128 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 128 512         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 128 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 128 512         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128, 128, 128 0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  33024       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 256)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 256)  1024        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 256)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 256)  1024        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 64, 256)  0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 256)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 256)  1024        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 64, 256)  0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 256)  590080      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 256)  0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 256)  1024        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 64, 64, 256)  0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 256)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 256)  1024        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 64, 64, 256)  0           conv2d_15[0][0]                  \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 128, 128, 128 295040      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 256 0           conv2d_transpose[0][0]           \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 128 295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 128, 128 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 128 512         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, 128, 128 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 128, 128, 128 512         activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 128, 128, 128 0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 128 512         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 128, 128, 128 0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 128 512         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 128, 128, 128 0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 128 147584      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 128, 128, 128 0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 128 512         activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 128, 128, 128 0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128, 128, 128 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 128, 128, 128 512         activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 256, 256, 64) 73792       conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 128 147584      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 256, 256, 128 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256, 256, 128 512         activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 128 147584      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256, 256, 128 0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256, 256, 128 512         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 256, 256, 128 0           batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256, 256, 128 512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 128 147584      batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 256, 256, 128 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 256, 256, 128 512         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 256, 256, 128 0           batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 128 147584      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 256, 256, 128 0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 256, 256, 128 512         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 256, 256, 128 0           batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 256, 128 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256, 256, 128 512         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 64) 73792       batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 512, 512, 32) 18464       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512, 512, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 512, 512, 128 73856       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 512, 512, 128 0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 512, 512, 128 512         activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 512, 512, 128 147584      batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 512, 512, 128 0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 512, 512, 128 512         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 512, 512, 128 0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 512, 512, 128 512         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 512, 512, 128 147584      batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 512, 512, 128 0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 512, 512, 128 512         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 512, 512, 128 0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 512, 512, 128 147584      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 512, 512, 128 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 512, 512, 128 512         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 512, 512, 128 0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 512, 512, 128 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 512, 512, 128 512         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 512, 512, 32) 36896       batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 512, 512, 1)  33          conv2d_34[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,690,785\n",
      "Trainable params: 5,680,417\n",
      "Non-trainable params: 10,368\n",
      "__________________________________________________________________________________________________\n",
      "Train: 60 - 60\r\n",
      "Valid: 10 - 10\n",
      "Epoch 1/150\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 1.5416 - dice_coef: 0.1497 - iou: 0.0809 - recall: 0.6908 - precision: 0.1774WARNING:tensorflow:From C:\\Users\\aqsas\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 6/30 [=====>........................] - ETA: 7:19 - loss: 1.4588 - dice_coef: 0.2270 - iou: 0.1288 - recall: 0.7461 - precision: 0.2996"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# RCNN\n",
    "def Rec_conv2d_bn(x, nb_filter, nb_row, nb_col,border_mode='same',strides=(1, 1),name=None):\n",
    "    '''Utility function to apply conv + BN.\n",
    "    '''\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "        \n",
    "    #if K.image_dim_ordering() == 'tf':\n",
    "    bn_axis = 3\n",
    "    #kernal_initializer = tf.keras.initializers.HeNormal()\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                      padding=border_mode,\n",
    "                      name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x)\n",
    "    x1=tf.keras.layers.Activation('relu')(x1)   \n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                      padding=border_mode,\n",
    "                      name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x1)              \n",
    "    x2=tf.keras.layers.Activation('relu')(x2)  \n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    x12 = tf.keras.layers.add([x1, x2])\n",
    "    x12 = tf.keras.layers.BatchNormalization()(x12)\n",
    "    \n",
    "    x3 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                      padding=border_mode,\n",
    "                      name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x12) \n",
    "    x3=tf.keras.layers.Activation('relu')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "    x13 = tf.keras.layers.add([x1, x3])\n",
    "\n",
    "    x4 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                      padding='same',\n",
    "                      name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x13)\n",
    "    x4=tf.keras.layers.Activation('relu')(x4) \n",
    "    x4 = tf.keras.layers.BatchNormalization()(x4)\n",
    "\n",
    "   \n",
    "    x14 = tf.keras.layers.add([x1, x4])\n",
    "    \n",
    "   # x5 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                    #  padding='same',\n",
    "                    #  name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x14)\n",
    "   # x5=tf.keras.layers.Activation('relu')(x5) \n",
    "  #  x5 = tf.keras.layers.BatchNormalization()(x5)\n",
    "\n",
    "   \n",
    "   # x15 = tf.keras.layers.add([x1, x5])\n",
    "    \n",
    "   # x6 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                     # padding='same',\n",
    "                     # name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x15)\n",
    "    #x6=tf.keras.layers.Activation('relu')(x5) \n",
    "    #x6 = tf.keras.layers.BatchNormalization()(x5)\n",
    "    #x16 = tf.keras.layers.add([x1, x6])\n",
    "    \n",
    "    #x7 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "     #                 padding='same',\n",
    "      #                name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x16)\n",
    "    #x7=tf.keras.layers.Activation('relu')(x6) \n",
    "    #x7 = tf.keras.layers.BatchNormalization()(x6)   \n",
    "    #x17 = tf.keras.layers.add([x1, x7])\n",
    "    \n",
    "   # x8 = tf.keras.layers.Conv2D(nb_filter, (nb_row, nb_col),strides=strides,\n",
    "                      #padding='same',\n",
    "                     # name=conv_name,kernel_regularizer=tf.keras.regularizers.l2(0.0002),data_format='channels_last')(x17)\n",
    "    #x8=tf.keras.layers.Activation('relu')(x7) \n",
    "    #x8 = tf.keras.layers.BatchNormalization()(x7)   \n",
    "    #x18 = tf.keras.layers.add([x1, x8])\n",
    "    #x = Dropout(0.2)(x18)\n",
    "    x=tf.keras.layers.Activation('relu')(x14) \n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name)(x)\n",
    "    return x\n",
    "\n",
    "def build_R2UNetED(input_shape):\n",
    "      \n",
    "\n",
    "    channel_axis = 3\n",
    "    inputs =  tf.keras.Input(input_shape) \n",
    "\n",
    "    # first block\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(inputs)    \n",
    "    rcnn_bn1 = Rec_conv2d_bn(x, 32, 3, 3)    \n",
    "    conv1_f = tf.keras.layers.add([x, rcnn_bn1])\n",
    "\n",
    "    # downsampling first block..\n",
    "    pool1 = tf.keras.layers.MaxPooling2D((2, 2),data_format='channels_last')(conv1_f)\n",
    "    conv_pool1 = tf.keras.layers.Conv2D(64, (1, 1), activation='relu', padding='same',data_format='channels_last')(pool1)\n",
    "    \n",
    "    # second RRCNN layer...\n",
    "    rcnn_bn2 = Rec_conv2d_bn(conv_pool1, 64, 3, 3)    \n",
    "    conv2_f = tf.keras.layers.add([conv_pool1, rcnn_bn2])\n",
    "    \n",
    "    # downsampling first block..\n",
    "    pool2 = tf.keras.layers.MaxPooling2D((2, 2),data_format='channels_last')(conv2_f)\n",
    "    conv_pool2 = tf.keras.layers.Conv2D(128, (1, 1), activation='relu', padding='same',data_format='channels_last')(pool2)\n",
    "    \n",
    "    # third RRCNN layer...\n",
    "    rcnn_bn3 = Rec_conv2d_bn(conv_pool2, 128, 3, 3)    \n",
    "    conv3_f = tf.keras.layers.add([conv_pool2, rcnn_bn3])\n",
    "    \n",
    "    # downsampling first block..\n",
    "    pool3 = tf.keras.layers.MaxPooling2D((2, 2),data_format='channels_last')(conv3_f)\n",
    "    conv_pool3 = tf.keras.layers.Conv2D(256, (1, 1), activation='relu', padding='same',data_format='channels_last')(pool3)\n",
    "    \n",
    "    # fourth RRCNN layer...\n",
    "    rcnn_bn4 = Rec_conv2d_bn(conv_pool3, 256, 3, 3)    \n",
    "    conv4_f = tf.keras.layers.add([conv_pool3, rcnn_bn4])\n",
    "      \n",
    "    # Decoder...\n",
    "    \n",
    "    up7_1 = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same',data_format='channels_last')(conv4_f)\n",
    "    up7 = tf.keras.layers.concatenate([up7_1, conv3_f], axis=channel_axis)\n",
    "    up7 = Rec_conv2d_bn(up7,128, 3, 3)\n",
    "    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_last')(up7)\n",
    "    #conv7 = Conv2D(128, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv7)\n",
    "    \n",
    "    up8_1 =tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same',data_format='channels_last')(conv7)\n",
    "    up8 = tf.keras.layers.concatenate([up8_1, conv2_f], axis=channel_axis)\n",
    "    up8 = Rec_conv2d_bn(up8,128, 3, 3)\n",
    "    conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_last')(up8)\n",
    "    #conv8 = Conv2D(64, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv8)\n",
    "    \n",
    "    up9_1 = tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same',data_format='channels_last')(conv8)\n",
    "    up9 = tf.keras.layers.concatenate([up9_1, conv1_f], axis=channel_axis)\n",
    "    up9 = Rec_conv2d_bn(up9,128, 3, 3)\n",
    "    conv9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(up9)\n",
    "    #conv9 = Conv2D(32, (3, 3), activation='relu', padding='same',data_format='channels_last')(conv9)\n",
    "    \n",
    "   \n",
    "    conv10 = tf.keras.layers.Conv2D(1,1, padding = \"same\", activation='sigmoid')(conv9)\n",
    "       \n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "   #model.compile(optimizer=Adam(2e-4),loss=dice_coef_loss,metrics = [dice_coef, 'acc', 'mse'])\n",
    "    \n",
    "   #model.compile(optimizer=tf.train.AdamOptimizer(3e-4), loss='binary_crossentropy',metrics = ['acc', 'mse'])\n",
    "    \n",
    "    return model \n",
    "\n",
    "\n",
    "input_shape = (512, 512, 3)\n",
    "model = build_R2UNetED(input_shape)\n",
    "model.summary()\n",
    "    ########################################\n",
    "\n",
    "import os   \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "#from model import build_unet\n",
    "#from metrics import dice_loss, dice_coef, iou\n",
    "\n",
    "H = 512\n",
    "W = 512\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_data(path):\n",
    "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
    "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
    "    return x, y\n",
    "\n",
    "def shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state=42)\n",
    "    return x, y\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "    # x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch_size=2):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(4)\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    set_seed = 42\n",
    "    np.random.set_seed = set_seed\n",
    "    \n",
    "\n",
    "    \"\"\" Directory to save files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 2\n",
    "    lr = 1e-4\n",
    "\n",
    "    num_epochs = 150\n",
    "    model_path = os.path.join(\"files\", \"model.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"data.csv\")\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"new_data\"\n",
    "    train_path = os.path.join(dataset_path, \"train\")\n",
    "    valid_path = os.path.join(dataset_path, \"test\")\n",
    "\n",
    "    train_x, train_y = load_data(train_path)\n",
    "    train_x, train_y = shuffling(train_x, train_y)\n",
    "    valid_x, valid_y = load_data(valid_path)\n",
    "\n",
    "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
    "\n",
    "    train_steps = len(train_x)//batch_size\n",
    "    valid_setps = len(valid_x)//batch_size\n",
    "\n",
    "    if len(train_x) % batch_size != 0:\n",
    "        train_steps += 1\n",
    "    if len(valid_x) % batch_size != 0:\n",
    "        valid_setps += 1\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = build_R2UNetED((H, W, 3))\n",
    "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
    "    # model.summary()\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        TensorBoard(),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=valid_setps,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "#from keras import Dropout\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "#from metrics import dice_loss, dice_coef, iou\n",
    "\n",
    "H = 512\n",
    "W = 512\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    # x = cv2.resize(x, (W, H))\n",
    "    ori_x = x\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return ori_x, x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
    "    # x = cv2.resize(x, (W, H))\n",
    "    ori_x = x\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.int32)\n",
    "    return ori_x, x\n",
    "\n",
    "def load_data(path):\n",
    "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
    "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
    "    return x, y\n",
    "\n",
    "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
    "    line = np.ones((H, 10, 3)) * 255\n",
    "\n",
    "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
    "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
    "\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255\n",
    "\n",
    "    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n",
    "    cv2.imwrite(save_image_path, cat_images)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Save the results in this folder \"\"\"\n",
    "    create_dir(\"results\")\n",
    "\n",
    "    \"\"\" Load the model \"\"\"\n",
    "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
    "        model = tf.keras.models.load_model(\"files/model.h5\")\n",
    "\n",
    "    \"\"\" Load the dataset \"\"\"\n",
    "    dataset_path = os.path.join(\"new_data\", \"test\")\n",
    "    test_x, test_y = load_data(dataset_path)\n",
    "\n",
    "    \"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
    "    SCORE = []\n",
    "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
    "        \"\"\" Extracting name \"\"\"\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0] \n",
    "\n",
    "        \"\"\" Read the image and mask \"\"\"\n",
    "        ori_x, x = read_image(x)\n",
    "        ori_y, y = read_mask(y)\n",
    "\n",
    "        \"\"\" Prediction \"\"\"\n",
    "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
    "        y_pred = y_pred > 0.5\n",
    "        y_pred = y_pred.astype(np.int32)\n",
    "        y_pred = np.squeeze(y_pred, axis=-1)\n",
    "\n",
    "        \"\"\" Saving the images \"\"\"\n",
    "        save_image_path = f\"results/{name}.png\"\n",
    "        save_results(ori_x, ori_y, y_pred, save_image_path)\n",
    "\n",
    "        \"\"\" Flatten the array \"\"\"\n",
    "        y = y.flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "\n",
    "        \"\"\" Calculate the metrics \"\"\"\n",
    "        acc_value = accuracy_score(y, y_pred)\n",
    "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
    "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
    "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
    "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
    "        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
    "\n",
    "    score = [s[1:] for s in SCORE]\n",
    "    score = np.mean(score, axis=0)\n",
    "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
    "    print(f\"F1: {score[1]:0.5f}\")\n",
    "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
    "    print(f\"Recall: {score[3]:0.5f}\")\n",
    "    print(f\"Precision: {score[4]:0.5f}\")\n",
    "\n",
    "    \"\"\" Saving \"\"\"\n",
    "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
    "    df.to_csv(\"files/score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cf3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
